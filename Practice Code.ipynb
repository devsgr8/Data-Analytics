{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Last amended:06th Sep, 2022\n",
    "#  Myfolder: /home/ashok/Documents/spark\n",
    "# Ref:\n",
    "# Tutorials (slightly dated):\n",
    "#      https://changhsinlee.com/pyspark-dataframe-basics/\n",
    "#      https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n",
    "# Cheat Sheet\n",
    "#      https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf\n",
    "\n",
    "#  Objectives:\n",
    "#           Dataframe operations in spark cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyspark APIs<br>\n",
    "> i)  [DataFrame APIs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis)<br>\n",
    ">> df.select(columnName).where(colObject > 30).orderBy(desc(columnName))<br>\n",
    ">> df.select(columnName).where(\"colName > 30\").orderBy(desc(columnName))<br>\n",
    "\n",
    "> ii) [Column APIs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#column-apis)<br>\n",
    ">> df.select(df.age.isNull())<br>\n",
    ">> df.select(df[\"age\"].isNull())<br>\n",
    ">> df.select(col(\"age\").isNull())<br>\n",
    "\n",
    "> iii)[Data Tyoes](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types)<br>\n",
    "> iv) [Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions)<br>\n",
    ">> df.select(sum(\"age\"))<br>\n",
    ">> df.select(sum(col(booleanColumn).cast(\"int\")))<br>\n",
    ">> <u>but you must import the functions</u>\n",
    "\n",
    "> v)  [Grouping](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#grouping)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Initial operations:\n",
    "1.0 Start hadoop in a terminal:\n",
    "\n",
    "            ./allstart.sh\n",
    "            OR\n",
    "            ./quick_allstart.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer files to hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 ashok supergroup    4582364 2022-10-11 13:59 /user/ashok/datadir/blackfridayless.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Transfer data file 'blackfridayless.csv' to hadoop\n",
    "#     Linux File folder:  /cdata/misc_datasets/black_friday\n",
    "#     In Hadoop first make a folder: /user/ashok/datadir \n",
    "#     and then transfer the file 'blackfridayless.csv' to \n",
    "#     this folder: /user/ashok/datadir\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cd ~\n",
    "hdfs dfs -rm -f -r  /user/ashok/datadir\n",
    "hdfs dfs -mkdir /user/ashok/datadir\n",
    "hdfs dfs -put /cdata/misc_datasets/black_friday/blackfridayless.csv  /user/ashok/datadir\n",
    "hdfs dfs -ls /user/ashok/datadir\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "!cd ~\n",
    "!hdfs dfs -rm -f -r  /user/ashok/datadir\n",
    "!hdfs dfs -mkdir /user/ashok/datadir\n",
    "!hdfs dfs -put /cdata/misc_datasets/black_friday/blackfridayless.csv  /user/ashok/datadir\n",
    "!hdfs dfs -ls /user/ashok/datadir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set jupyter notebook options\n",
    "Start pyspark with jupyter notebook interface. There is no need to create SparkContext and Spark session. pyspark creates them when starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Display multiple outputs from a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4533/4238029408.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.3 Increase cell width to display wide columnar output\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv file from hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Read file 'blackfridayless.csv' from hadoop\n",
    "\n",
    "# 2.0 What is the URL of folder in hadoop where blackfriday file existshaving the file?\n",
    "#     url: \"hdfs://localhost:9000/<folderPath>\"\n",
    "\n",
    "\n",
    "URL_of_folder= \"hdfs://localhost:9000/user/ashok/datadir/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 2.1 Read the file blackfridayless.csv. Takes time.\n",
    "#      Use 'spark.read.csv' session object to read file:\n",
    "#       Here is reading template:\n",
    "\n",
    "blackfriday = spark.read.csv(\n",
    "                             path = URL_of_folder + \"blackfridayless.csv\" ,\n",
    "                             inferSchema = True,                # True or False\n",
    "                             header = True,                   # True or False\n",
    "                             sep = \",\",                        # Which one: , ;, | etc\n",
    "                             ignoreLeadingWhiteSpace = True,    # True or False\n",
    "                             ignoreTrailingWhiteSpace = True     # True of False\n",
    "    \n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1000001, productId='P00069042', gender='F', age='0-17', occupation=10, cityCategory='A', stayCityYears='2', maritalStatus=0, productCat1=3, productCat2=None, productCat3=None, purchase=8370),\n",
       " Row(userId=1000001, productId='P00248942', gender='F', age='0-17', occupation=10, cityCategory='A', stayCityYears='2', maritalStatus=0, productCat1=1, productCat2=6, productCat3=14, purchase=15200),\n",
       " Row(userId=1000001, productId='P00087842', gender='F', age='0-17', occupation=10, cityCategory='A', stayCityYears='2', maritalStatus=0, productCat1=12, productCat2=None, productCat3=None, purchase=1422),\n",
       " Row(userId=1000001, productId='P00085442', gender='F', age='0-17', occupation=10, cityCategory='A', stayCityYears='2', maritalStatus=0, productCat1=12, productCat2=14, productCat3=None, purchase=1057),\n",
       " Row(userId=1000002, productId='P00285442', gender='M', age='55+', occupation=16, cityCategory='C', stayCityYears='4+', maritalStatus=0, productCat1=8, productCat2=None, productCat3=None, purchase=7969)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "| userId|productId|gender| age|occupation|cityCategory|stayCityYears|maritalStatus|productCat1|productCat2|productCat3|purchase|\n",
      "+-------+---------+------+----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "|1000001|P00069042|     F|0-17|        10|           A|            2|            0|          3|       null|       null|    8370|\n",
      "|1000001|P00248942|     F|0-17|        10|           A|            2|            0|          1|          6|         14|   15200|\n",
      "|1000001|P00087842|     F|0-17|        10|           A|            2|            0|         12|       null|       null|    1422|\n",
      "+-------+---------+------+----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Show five rows of data:\n",
    "blackfriday.head(5)\n",
    "blackfriday.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId',\n",
       " 'productId',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'occupation',\n",
       " 'cityCategory',\n",
       " 'stayCityYears',\n",
       " 'maritalStatus',\n",
       " 'productCat1',\n",
       " 'productCat2',\n",
       " 'productCat3',\n",
       " 'purchase']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 Show data columns\n",
    "\n",
    "blackfriday.columns\n",
    "len(blackfriday.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'int'),\n",
       " ('productId', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('age', 'string'),\n",
       " ('occupation', 'int'),\n",
       " ('cityCategory', 'string'),\n",
       " ('stayCityYears', 'string'),\n",
       " ('maritalStatus', 'int'),\n",
       " ('productCat1', 'int'),\n",
       " ('productCat2', 'int'),\n",
       " ('productCat3', 'int'),\n",
       " ('purchase', 'int')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 Show dtypes:\n",
    "blackfriday.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- productId: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- cityCategory: string (nullable = true)\n",
      " |-- stayCityYears: string (nullable = true)\n",
      " |-- maritalStatus: integer (nullable = true)\n",
      " |-- productCat1: integer (nullable = true)\n",
      " |-- productCat2: integer (nullable = true)\n",
      " |-- productCat3: integer (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.5 Print schema of blackfriday:\n",
    "\n",
    "blackfriday.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackfriday[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "| age|occupation|\n",
      "+----+----------+\n",
      "|0-17|        10|\n",
      "|0-17|        10|\n",
      "|0-17|        10|\n",
      "+----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blackfriday.select('age','occupation').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----------------+\n",
      "|summary|   age|gender|       occupation|\n",
      "+-------+------+------+-----------------+\n",
      "|  count|100887|100887|           100887|\n",
      "|   mean|  null|  null|8.086631577903992|\n",
      "| stddev|  null|  null|6.529747259316683|\n",
      "|    min|  0-17|     F|                0|\n",
      "|    max|   55+|     M|               20|\n",
      "+-------+------+------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 3.0 Describe the statistics of data, few columns at a time:\n",
    "\n",
    "blackfriday.select('age','gender','occupation').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5801"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|  age|\n",
      "+-----+\n",
      "|18-25|\n",
      "|26-35|\n",
      "| 0-17|\n",
      "|46-50|\n",
      "|51-55|\n",
      "|36-45|\n",
      "|  55+|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Count How many distinct userids are there \n",
    "#     Use distinct() and count()\n",
    "\n",
    "blackfriday.select('userId').distinct().count()\n",
    "\n",
    "blackfriday.select('age').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Count how many distinct age-groups exist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0 How many null values occur in each column\n",
    "\n",
    "from pyspark.sql.functions import isnan, isnull,col, sum, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|     0|\n",
      "+------+\n",
      "\n",
      "+---------+\n",
      "|productId|\n",
      "+---------+\n",
      "|        0|\n",
      "+---------+\n",
      "\n",
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     0|\n",
      "+------+\n",
      "\n",
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "|  0|\n",
      "+---+\n",
      "\n",
      "+----------+\n",
      "|occupation|\n",
      "+----------+\n",
      "|         0|\n",
      "+----------+\n",
      "\n",
      "+------------+\n",
      "|cityCategory|\n",
      "+------------+\n",
      "|           0|\n",
      "+------------+\n",
      "\n",
      "+-------------+\n",
      "|stayCityYears|\n",
      "+-------------+\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|maritalStatus|\n",
      "+-------------+\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-----------+\n",
      "|productCat1|\n",
      "+-----------+\n",
      "|          0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|productCat2|\n",
      "+-----------+\n",
      "|      31429|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|productCat3|\n",
      "+-----------+\n",
      "|      70100|\n",
      "+-----------+\n",
      "\n",
      "+--------+\n",
      "|purchase|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "for i in blackfriday.columns:\n",
    "    blackfriday.select(sum(col(i).isNull().alias(\"nullcol\").cast(\"int\")).alias(i)).show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns have null values. Most probably it means that there is no sub-category or sub-categories present. <br>\n",
    "How would you plan to fill them?<br>\n",
    "productCat1 :  0 <br>\n",
    "productCat2 :  31429 <br>\n",
    "productCat3 :  70100 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId',\n",
       " 'occupation',\n",
       " 'maritalStatus',\n",
       " 'productCat1',\n",
       " 'productCat2',\n",
       " 'productCat3',\n",
       " 'purchase']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.0 Get a list of all integer columns and string columns\n",
    "#     Use list comprhension along with dtypes:\n",
    "[    i[0]       for i in blackfriday.dtypes if i[1]=='int']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('productId', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('age', 'string'),\n",
       " ('cityCategory', 'string'),\n",
       " ('stayCityYears', 'string')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[    i           for i in blackfriday.dtypes if i[1]=='string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(productCat2)|\n",
      "+----------------+\n",
      "|              18|\n",
      "+----------------+\n",
      "\n",
      "+----------------+\n",
      "|max(productCat3)|\n",
      "+----------------+\n",
      "|              18|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Display maximum of productCat2 and productCat3\n",
    "#     Use select() along with 'max' function\n",
    "\n",
    "\n",
    "#blackfriday.select('productCat2').max()\n",
    "blackfriday.select(max('productCat2')).show()\n",
    "blackfriday.select(max('productCat3')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|max(occupation)|\n",
      "+---------------+\n",
      "|             20|\n",
      "+---------------+\n",
      "\n",
      "+---------------+\n",
      "|min(occupation)|\n",
      "+---------------+\n",
      "|              0|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Find minimum and max values of 'occupation' column\n",
    "\n",
    "blackfriday.select(max('occupation')).show()\n",
    "blackfriday.select(min('occupation')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "| userId|productId|gender|  age|occupation|cityCategory|stayCityYears|maritalStatus|productCat1|productCat2|productCat3|purchase|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "|1000001|P00069042|     F| 0-17|        10|           A|            2|            0|          3|        999|        999|    8370|\n",
      "|1000001|P00248942|     F| 0-17|        10|           A|            2|            0|          1|          6|         14|   15200|\n",
      "|1000001|P00087842|     F| 0-17|        10|           A|            2|            0|         12|        999|        999|    1422|\n",
      "|1000001|P00085442|     F| 0-17|        10|           A|            2|            0|         12|         14|        999|    1057|\n",
      "|1000002|P00285442|     M|  55+|        16|           C|           4+|            0|          8|        999|        999|    7969|\n",
      "|1000003|P00193542|     M|26-35|        15|           A|            3|            0|          1|          2|        999|   15227|\n",
      "|1000004|P00184942|     M|46-50|         7|           B|            2|            1|          1|          8|         17|   19215|\n",
      "|1000004|P00346142|     M|46-50|         7|           B|            2|            1|          1|         15|        999|   15854|\n",
      "|1000004| P0097242|     M|46-50|         7|           B|            2|            1|          1|         16|        999|   15686|\n",
      "|1000005|P00274942|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    7871|\n",
      "|1000005|P00251242|     M|26-35|        20|           A|            1|            1|          5|         11|        999|    5254|\n",
      "|1000005|P00014542|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    3957|\n",
      "|1000005|P00031342|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    6073|\n",
      "|1000005|P00145042|     M|26-35|        20|           A|            1|            1|          1|          2|          5|   15665|\n",
      "|1000006|P00231342|     F|51-55|         9|           A|            1|            0|          5|          8|         14|    5378|\n",
      "|1000006|P00190242|     F|51-55|         9|           A|            1|            0|          4|          5|        999|    2079|\n",
      "|1000006| P0096642|     F|51-55|         9|           A|            1|            0|          2|          3|          4|   13055|\n",
      "|1000006|P00058442|     F|51-55|         9|           A|            1|            0|          5|         14|        999|    8851|\n",
      "|1000007|P00036842|     M|36-45|         1|           B|            1|            1|          1|         14|         16|   11788|\n",
      "|1000008|P00249542|     M|26-35|        12|           C|           4+|            1|          1|          5|         15|   19614|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Fill null values in productCat2 and productCat3 with 999\n",
    "#     Use df.na.fill()\\\n",
    "\n",
    "blackfriday=blackfriday.na.fill(value=999, subset=[\"productCat2\", \"productCat3\"])\n",
    "blackfriday.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>cityCategory</th>\n",
       "      <th>stayCityYears</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>productCat1</th>\n",
       "      <th>productCat2</th>\n",
       "      <th>productCat3</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100882</th>\n",
       "      <td>1003618</td>\n",
       "      <td>P00359742</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>11660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100883</th>\n",
       "      <td>1003618</td>\n",
       "      <td>P00035142</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>11813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100884</th>\n",
       "      <td>1003618</td>\n",
       "      <td>P00207942</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>16020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100885</th>\n",
       "      <td>1003618</td>\n",
       "      <td>P00151142</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100886</th>\n",
       "      <td>1003618</td>\n",
       "      <td>P00178842</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100887 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  productId gender   age  occupation cityCategory  \\\n",
       "0       1000001  P00069042      F  0-17          10            A   \n",
       "1       1000001  P00248942      F  0-17          10            A   \n",
       "2       1000001  P00087842      F  0-17          10            A   \n",
       "3       1000001  P00085442      F  0-17          10            A   \n",
       "4       1000002  P00285442      M   55+          16            C   \n",
       "...         ...        ...    ...   ...         ...          ...   \n",
       "100882  1003618  P00359742      M   55+          17            A   \n",
       "100883  1003618  P00035142      M   55+          17            A   \n",
       "100884  1003618  P00207942      M   55+          17            A   \n",
       "100885  1003618  P00151142      M   55+          17            A   \n",
       "100886  1003618  P00178842      M   55+          17            A   \n",
       "\n",
       "       stayCityYears  maritalStatus  productCat1  productCat2  productCat3  \\\n",
       "0                  2              0            3          999          999   \n",
       "1                  2              0            1            6           14   \n",
       "2                  2              0           12          999          999   \n",
       "3                  2              0           12           14          999   \n",
       "4                 4+              0            8          999          999   \n",
       "...              ...            ...          ...          ...          ...   \n",
       "100882            4+              1            1            5          999   \n",
       "100883            4+              1            1            5          999   \n",
       "100884            4+              1            6            8          999   \n",
       "100885            4+              1            6           16          999   \n",
       "100886            4+              1            2            4            9   \n",
       "\n",
       "        purchase  \n",
       "0           8370  \n",
       "1          15200  \n",
       "2           1422  \n",
       "3           1057  \n",
       "4           7969  \n",
       "...          ...  \n",
       "100882     11660  \n",
       "100883     11813  \n",
       "100884     16020  \n",
       "100885      8460  \n",
       "100886     10101  \n",
       "\n",
       "[100887 rows x 12 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.0 Transform spark dataframe to pandas dataframe:\n",
    "#     Use df.toPandas()\n",
    "\n",
    "blackfriday.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|cityCategory|count|\n",
      "+------------+-----+\n",
      "|           B|42347|\n",
      "|           C|31071|\n",
      "|           A|27469|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Show a value count of levels of column 'cityCategory':\n",
    "#      Use groupby and count\n",
    "\n",
    "blackfriday.groupby('cityCategory').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.0 Perform a stratified sampling of data.\n",
    "#      Stratified sampling be by column: 'cityCategory'\n",
    "#        Take 80% from 'B' and 20% from 'C'\n",
    "\n",
    "sample = blackfriday.sampleBy(\n",
    "                      \"cityCategory\",      # column that defines strata\n",
    "                      fractions = {'B' : 0.8, 'C' : 0.2})   # sampling fraction for each stratum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using verbs\n",
    ">select, <br>\n",
    "><i>select(x).where()</i>,<br>\n",
    "><i>select().distinct()</i>,<br>\n",
    ">filter,<br>\n",
    ">groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select syntax\n",
    "> DataFrame.select(\\*cols)<br>\n",
    "> cols: column names (string) or expressions (Column). If one of the column names is ‘*’, that column is expanded to include all columns in the current DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+\n",
      "|gender| age|occupation|\n",
      "+------+----+----------+\n",
      "|     F|0-17|        10|\n",
      "|     F|0-17|        10|\n",
      "|     F|0-17|        10|\n",
      "+------+----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.0 Show columns 3rd till 5th\n",
    "\n",
    "blackfriday.select(blackfriday.columns[2:5]).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter syntax\n",
    ">DataFrame.filter(condition)<br>\n",
    ">condition: <i>columnObject > 34</i> or string format: <i>\"age > 34\"</i>\n",
    ">>  df.age > 3 or col(\"age\") > 3<br>\n",
    ">>  \"age > 3\" <br>\n",
    ">>Logical Operators<br>\n",
    ">>> If string: AND OR NOT<br>\n",
    ">>> If columnObject: &, |, ~ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "| userId|productId|gender|  age|occupation|cityCategory|stayCityYears|maritalStatus|productCat1|productCat2|productCat3|purchase|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "|1000001|P00069042|     F| 0-17|        10|           A|            2|            0|          3|        999|        999|    8370|\n",
      "|1000001|P00087842|     F| 0-17|        10|           A|            2|            0|         12|        999|        999|    1422|\n",
      "|1000001|P00085442|     F| 0-17|        10|           A|            2|            0|         12|         14|        999|    1057|\n",
      "|1000002|P00285442|     M|  55+|        16|           C|           4+|            0|          8|        999|        999|    7969|\n",
      "|1000005|P00274942|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    7871|\n",
      "|1000005|P00251242|     M|26-35|        20|           A|            1|            1|          5|         11|        999|    5254|\n",
      "|1000005|P00014542|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    3957|\n",
      "|1000005|P00031342|     M|26-35|        20|           A|            1|            1|          8|        999|        999|    6073|\n",
      "|1000006|P00231342|     F|51-55|         9|           A|            1|            0|          5|          8|         14|    5378|\n",
      "|1000006|P00190242|     F|51-55|         9|           A|            1|            0|          4|          5|        999|    2079|\n",
      "|1000006|P00058442|     F|51-55|         9|           A|            1|            0|          5|         14|        999|    8851|\n",
      "|1000008|P00220442|     M|26-35|        12|           C|           4+|            1|          5|         14|        999|    8584|\n",
      "|1000008|P00214442|     M|26-35|        12|           C|           4+|            1|          8|        999|        999|    5982|\n",
      "|1000009|P00039942|     M|26-35|        17|           C|            0|            0|          8|        999|        999|    5887|\n",
      "|1000009|P00161442|     M|26-35|        17|           C|            0|            0|          5|         14|        999|    6973|\n",
      "|1000009|P00078742|     M|26-35|        17|           C|            0|            0|          5|          8|         14|    5391|\n",
      "|1000010|P00118742|     F|36-45|         1|           B|           4+|            1|          5|         11|        999|    8886|\n",
      "|1000010|P00297942|     F|36-45|         1|           B|           4+|            1|          8|        999|        999|    5875|\n",
      "|1000010|P00266842|     F|36-45|         1|           B|           4+|            1|          5|        999|        999|    8854|\n",
      "|1000010|P00032442|     F|36-45|         1|           B|           4+|            1|          5|        999|        999|    5152|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Filter purchases less than 9000\n",
    "#      Use filter()\n",
    "\n",
    "blackfriday.filter(blackfriday.purchase < '9000').show()\n",
    "#condition: purchase < 9000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "| userId|productId|gender|  age|occupation|cityCategory|stayCityYears|maritalStatus|productCat1|productCat2|productCat3|purchase|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "|1000001|P00069042|     F| 0-17|        10|           A|            2|            0|          3|        999|        999|    8370|\n",
      "|1000001|P00087842|     F| 0-17|        10|           A|            2|            0|         12|        999|        999|    1422|\n",
      "|1000001|P00085442|     F| 0-17|        10|           A|            2|            0|         12|         14|        999|    1057|\n",
      "|1000002|P00285442|     M|  55+|        16|           C|           4+|            0|          8|        999|        999|    7969|\n",
      "|1000006|P00231342|     F|51-55|         9|           A|            1|            0|          5|          8|         14|    5378|\n",
      "|1000006|P00190242|     F|51-55|         9|           A|            1|            0|          4|          5|        999|    2079|\n",
      "|1000006|P00058442|     F|51-55|         9|           A|            1|            0|          5|         14|        999|    8851|\n",
      "|1000009|P00039942|     M|26-35|        17|           C|            0|            0|          8|        999|        999|    5887|\n",
      "|1000009|P00161442|     M|26-35|        17|           C|            0|            0|          5|         14|        999|    6973|\n",
      "|1000009|P00078742|     M|26-35|        17|           C|            0|            0|          5|          8|         14|    5391|\n",
      "|1000011|P00192642|     F|26-35|         1|           C|            1|            0|          8|         17|        999|    6171|\n",
      "|1000011|P00189642|     F|26-35|         1|           C|            1|            0|          8|         13|        999|    8027|\n",
      "|1000012|P00365242|     M|26-35|        12|           C|            2|            0|          5|          8|        999|    6865|\n",
      "|1000014|P00276642|     M|36-45|         0|           C|            0|            0|          8|         11|        999|    5848|\n",
      "|1000015|P00247542|     M|26-35|         7|           A|            1|            0|          8|         16|        999|    5958|\n",
      "|1000015|P00275142|     M|26-35|         7|           A|            1|            0|          5|          8|        999|    5380|\n",
      "|1000015|P00333042|     M|26-35|         7|           A|            1|            0|          5|          8|        999|    3594|\n",
      "|1000015|P00166242|     M|26-35|         7|           A|            1|            0|          8|        999|        999|    4209|\n",
      "|1000015|P00161942|     M|26-35|         7|           A|            1|            0|          5|          8|        999|    5407|\n",
      "|1000015|P00348242|     M|26-35|         7|           A|            1|            0|          8|        999|        999|    7803|\n",
      "+-------+---------+------+-----+----------+------------+-------------+-------------+-----------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Filter purchases less than 9000 and maritalStatus is 0\n",
    "\n",
    "blackfriday.filter((blackfriday.purchase < '9000')&(blackfriday.maritalStatus == '0')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3 Filter purchases less than 9000 or maritalStatus is 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|purchase|maritalStatus|\n",
      "+--------+-------------+\n",
      "|    8370|            0|\n",
      "|    1422|            0|\n",
      "|    1057|            0|\n",
      "|    7969|            0|\n",
      "|    7871|            1|\n",
      "|    5254|            1|\n",
      "|    3957|            1|\n",
      "|    6073|            1|\n",
      "|    5378|            0|\n",
      "|    2079|            0|\n",
      "|    8851|            0|\n",
      "|    8584|            1|\n",
      "|    5982|            1|\n",
      "|    5887|            0|\n",
      "|    6973|            0|\n",
      "|    5391|            0|\n",
      "|    8886|            1|\n",
      "|    5875|            1|\n",
      "|    8854|            1|\n",
      "|    5152|            1|\n",
      "+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+-------------+\n",
      "|purchase|maritalStatus|\n",
      "+--------+-------------+\n",
      "|    8757|            0|\n",
      "|    4102|            0|\n",
      "|    3713|            0|\n",
      "|    5269|            0|\n",
      "|    6396|            0|\n",
      "|    7074|            0|\n",
      "|    8764|            0|\n",
      "|    6007|            0|\n",
      "|    7536|            0|\n",
      "|    7945|            0|\n",
      "|    4691|            0|\n",
      "|    5332|            0|\n",
      "|    8653|            0|\n",
      "|    5194|            0|\n",
      "|    8849|            0|\n",
      "|     959|            0|\n",
      "|    5330|            0|\n",
      "|    8284|            0|\n",
      "|    4008|            0|\n",
      "|     946|            0|\n",
      "+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9.0 Combining verbs: select, filter and distinct\n",
    "\n",
    "blackfriday.select('purchase', 'maritalStatus'). \\\n",
    "            filter((blackfriday.purchase < '9000')). \\\n",
    "            show()\n",
    "\n",
    "# 10.1\n",
    "blackfriday.select('purchase', 'maritalStatus'). \\\n",
    "            filter((blackfriday.purchase < '9000')&(blackfriday.maritalStatus == '0')). \\\n",
    "            distinct(). \\\n",
    "            show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation with groupby\n",
    "Use: <i>.agg({'colName1' : 'mean', 'colName2' : 'sum'})</i> <br>\n",
    ">With <i>agg()</i> one can use only builtin functions and not any other <i>pyspark.sql.function</i>.<br>\n",
    "Some common functions are: <i>mean, avg, sum, count, first, last,stddev </i>. There is no need to import builtin function in advance.<br>\n",
    "For a complete list of builtin functions see [here](https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max of 'maritalStatus' and max of 'purchase'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'airports_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 12. groupby. Can apply sum, min, max, count\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mairports_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m      4\u001b[0m            count()\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m      5\u001b[0m            show(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 12.1\u001b[39;00m\n\u001b[1;32m      8\u001b[0m airports_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m      9\u001b[0m             agg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m     10\u001b[0m             show(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'airports_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 12. groupby. Can apply sum, min, max, count\n",
    "\n",
    "airports_df.groupby('tz'). \\\n",
    "           count(). \\\n",
    "           show(3)\n",
    "\n",
    "# 12.1\n",
    "airports_df.groupby('tz'). \\\n",
    "            agg({'lat' : 'mean'}). \\\n",
    "            show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUnpacking operator in python (*) : \\nRef: https://codeyarns.com/2012/04/26/unpack-operator-in-python/ \\n\\ndef fox(a,b):  \\n    return (a *b)  \\n\\nm = [3,4]  \\nfox(m)    \\nfox(*m)   \\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unpacking operator in python (*) : \n",
    "Ref: https://codeyarns.com/2012/04/26/unpack-operator-in-python/ \n",
    "\n",
    "def fox(a,b):  \n",
    "    return (a *b)  \n",
    "\n",
    "m = [3,4]  \n",
    "fox(m)    \n",
    "fox(*m)   \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'airports_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 12.2 One can take the average of columns by passing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#       an unpacked list of column names.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m grObject \u001b[38;5;241m=\u001b[39m \u001b[43mairports_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m avg_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m grObject\u001b[38;5;241m.\u001b[39mavg(\u001b[38;5;241m*\u001b[39mavg_cols)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'airports_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 12.2 One can take the average of columns by passing\n",
    "#       an unpacked list of column names.\n",
    "\n",
    "grObject = airports_df.groupby('tz')\n",
    "\n",
    "avg_cols = ['lat', 'lon']\n",
    "grObject.avg(*avg_cols).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grObject' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 12.3 To call multiple aggregation functions at once, pass a dictionary.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#         The 'key' of dictionary becomes argument to 'value'.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                             count(*)        avg(lat)      sum(lon)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mgrObject\u001b[49m\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grObject' is not defined"
     ]
    }
   ],
   "source": [
    "# 12.3 To call multiple aggregation functions at once, pass a dictionary.\n",
    "#         The 'key' of dictionary becomes argument to 'value'.\n",
    "#                             count(*)        avg(lat)      sum(lon)\n",
    "\n",
    "grObject.agg({'*': 'count', 'lat': 'avg', 'lon':'sum'}).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create new columns in Spark using .withColumn() --mutate\n",
    "#      New column: altInThousands . \n",
    "#      Product of two columns:  'alt' and  'lon' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save the new file with additional column in parquet form\n",
    "\n",
    "xyz = airports_df.withColumn('altInThousands', airports_df.alt*airports_df.lon)\n",
    "xyz.write.parquet(\"hdfs://localhost:9000/user/ashok/data_files/airports_extra.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Delete xyz from spark\n",
    "import gc\n",
    "del xyz\n",
    "gc.collect()    # Delete all cache also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 Read the stored parquet file\n",
    "df = spark.read.parquet(\"hdfs://localhost:9000/user/ashok/data_files/airports_extra.parquet\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 Read 'weather.csv file into spark from hadoop\n",
    "\n",
    "URL_of_file= \"hdfs://localhost:9000/user/ashok/data_files/nycflights/\"\n",
    "weather_df = spark.read.csv(path = URL_of_file + \"weather.csv\",\n",
    "                            inferSchema = True,\n",
    "                            header = True\n",
    "                           )\n",
    "weather_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Joins\n",
    "# Refer: http://www.learnbymarketing.com/1100/pyspark-joins-by-example/\n",
    "# For example, I can join the two titanic dataframes by the column PassengerId\n",
    "\n",
    "# 10.1\n",
    "airports_df.join(weather_df, airports_df.faa==weather_df.origin).show(3)\n",
    "# 10.2\n",
    "airports_df.join(weather_df, airports_df.faa==weather_df.origin, how = 'inner').show(3)\n",
    "# 10.3\n",
    "airports_df.join(weather_df, airports_df.faa==weather_df.origin, how = 'left').show(3)   # Could also use 'left_outer', 'right', 'full'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL queries against DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Many of the operations can be accessed by writing SQL queries in spark.sql().\n",
    "# To make an existing Spark dataframe usable for spark.sql(), one needs to\n",
    "#   register said dataframe as a temporary table.\n",
    "\n",
    "# 11.1 As an example, we can register the two dataframes as temp tables then\n",
    "#      join them through spark.sql().\n",
    "\n",
    "airports_df.createOrReplaceTempView('dfa_temp')\n",
    "weather_df.createOrReplaceTempView('dfw_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.2 Simple SQL query. SQLContext is no longer needed. 'spark'\n",
    "#            session object can be used.\n",
    "\n",
    "dfj = spark.sql('select * from dfa_temp' )\n",
    "dfj.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.3 Now the SQL join\n",
    "\n",
    "dfj = spark.sql('select * from dfa_temp a, dfw_temp b where a.faa = b.origin' )\n",
    "dfj.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Drop a columns\n",
    "\n",
    "airports_df.drop('name').show(3)\n",
    "\n",
    "# 12.1  Or drop multiple columns\n",
    "\n",
    "columns_to_drop = ['name', 'lat']\n",
    "xx =airports_df.drop(*columns_to_drop)\n",
    "xx.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### I am done ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
