{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last amended: 23th Sep, 2022\n",
    "# My folder: /home/ashok/Documents/spark/2.ml/1.demo\n",
    "##   Objectives:\n",
    "##  \t\ti)  Usage of StringIndexer, OneHotEncoder\n",
    "##              and VectorAssembler\n",
    "##          ii) Data Transformations\n",
    "##         iii) Modeling\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broad Steps\n",
    "1. Transform categorical data to integers (indices) using StringIndexer\n",
    "2. Transform indicies to OHE form\n",
    "3. Transform target seprately to integers (indices) using StrinIndexer\n",
    "4. Collect all numeric and OHE features in one place using VectorAssembler\n",
    "5. Perform modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small steps\n",
    "1. Transform categorical data to integers (indices) using StringIndexer\n",
    "> i) Create a list of categorical features<br>\n",
    ">ii) Create a StringIndexer object<br>\n",
    ">iii)Fit and transform using this object <br>\n",
    "\n",
    "2. Transform indices to OHE form<br>\n",
    ">i) Instantiate  an OHE object<br>\n",
    ">ii)Fit and transform indices createdas a result of 1(iii) above<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer files to hadoop\n",
    "Start hadoop and issue the following three commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 Transfer bplm.csv.gz to hadoop and check, as:\n",
    "\n",
    "\n",
    "! hdfs dfs -rm hdfs://localhost:9000/user/ashok/bplm.csv.gz\n",
    "! hdfs dfs -put /cdata/misc_datasets/bank_loan_modeling/bplm.csv.gz  hdfs://localhost:9000/user/ashok\n",
    "! hdfs dfs -ls hdfs://localhost:9000/user/ashok   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.0 Call libraries\n",
    "# 1.1   For transforming categorical data to integer and to dummy\n",
    "#       And for collecting all features at one place\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import  StringIndexer, OneHotEncoder ,VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Logistic Regression modeling:\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 For evaluating results:\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Read bank data:\n",
    "\n",
    "df  =   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Display df data, few at a time: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 Get data types:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Wrire here: \n",
    "#            a) list of cat columns\n",
    "#            b) list of index_col names; cat_cols => index_cols\n",
    "#            c) List of ohe Col names\n",
    "#        and d) numeric columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_cols    =\n",
    "index_cols  = \n",
    "ohe_cols    = \n",
    "num_cols    = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndex cat columns\n",
    "StringIndex cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3  Integer index string columns:\n",
    "# 2.3.1 Instantiate StringIndex class:\n",
    "\n",
    "si = StringIndexer(\n",
    "                     inputCols = ,\n",
    "                     outputCols = \n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2 Train/fit StringIndexer object:\n",
    "\n",
    "model = si.____(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.3 Transform data and observe:\n",
    "\n",
    "\n",
    "df = model.____(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 One hot encoding of string indexed columns:\n",
    "#     Instantiate OneHotEncoder class\n",
    "\n",
    "\n",
    "ohe =    OneHotEncoder(\n",
    "                       inputCols = \n",
    "                       outputCols =  \n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Fit the data to get 'ohe' object:\n",
    "\n",
    "model_ohe = ___.fit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Transform the data using model_ohe:\n",
    "\n",
    "\n",
    "df = model_ohe._________(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndex target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0 Indexing target separately\n",
    "#      Target is 'creditcard'\n",
    "#     Instantiate StringIndexer\n",
    "\n",
    "\n",
    "si_t = StringIndexer( inputCol =',\n",
    "                      outputCol = 'label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1: Fit StringIndexer object on target\n",
    "\n",
    "\n",
    "model_label = si_t.fit(______)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Transform target:\n",
    "\n",
    "df = model_label.transform( ________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Vector Assemble all predictors and transformed features\n",
    "\n",
    "vc = VectorAssembler(\n",
    "                    inputCols =  ,\n",
    "                    outputCol = 'features'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Transform df using 'vc' object:\n",
    "\n",
    "df = ________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Develop logisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.0 Instantiate Logistic Regression Class\n",
    "\n",
    "lr = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Train/fit Logistic class\n",
    "\n",
    "model_lr = ________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.0 Make predictions on df \n",
    "#     itself using transform() method\n",
    "#     (There is no predict() method)\n",
    "\n",
    "df = model_lr.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 See prediction dataframe columns\n",
    "\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.  We can make use of the BinaryClassificationEvaluator method to\n",
    "#     evaluate our model.\n",
    "#     The Evaluator expects two input columns: (rawPrediction, label)\n",
    "#     and a value of 'metricName'\n",
    "#     By default -label- parameter has value 'label', 'metricName'\n",
    "#     has value of \"areaUnderROC\"\n",
    "\n",
    "# 8.1 Instantiate evaluate class\n",
    "\n",
    "bc = BinaryClassificationEvaluator()\n",
    "\n",
    "# 8.2 Evaluate to retun performance\n",
    "\n",
    "\n",
    "__________________\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
